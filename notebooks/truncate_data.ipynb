{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aef8aef4",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "# Set paths\n",
                "DATA_DIR = r\"e:\\BSK-SER\\BSK-SER\\data\"\n",
                "CITIZEN_FILE = os.path.join(DATA_DIR, \"ml_citizen_master.csv\")\n",
                "PROVISION_FILE = os.path.join(DATA_DIR, \"ml_provision.csv\")\n",
                "FINAL_DF_FILE = os.path.join(DATA_DIR, \"final_df.csv\")\n",
                "\n",
                "# Target size\n",
                "TARGET_SIZE_MB = 45\n",
                "BYTES_PER_MB = 1024 * 1024\n",
                "TARGET_SIZE_BYTES = TARGET_SIZE_MB * BYTES_PER_MB\n",
                "\n",
                "def truncate_file(file_path):\n",
                "    if not os.path.exists(file_path):\n",
                "        print(f\"File not found: {file_path}\")\n",
                "        return\n",
                "\n",
                "    file_size = os.path.getsize(file_path)\n",
                "    file_size_mb = file_size / BYTES_PER_MB\n",
                "    print(f\"Processing {os.path.basename(file_path)}...\")\n",
                "    print(f\"  Current Size: {file_size_mb:.2f} MB\")\n",
                "\n",
                "    if file_size <= TARGET_SIZE_BYTES:\n",
                "        print(\"  Size is already under limit. Skipping.\")\n",
                "        return\n",
                "\n",
                "    # Estimate rows to keep\n",
                "    try:\n",
                "        # Sample first 1000 rows to get average bytes per row\n",
                "        sample_df = pd.read_csv(file_path, nrows=1000, encoding='latin-1')\n",
                "        sample_csv = sample_df.to_csv(index=False)\n",
                "        sample_size = len(sample_csv)\n",
                "        avg_bytes_per_row = sample_size / 1000\n",
                "        \n",
                "        target_rows = int(TARGET_SIZE_BYTES / avg_bytes_per_row)\n",
                "        print(f\"  Estimated target rows: {target_rows}\")\n",
                "        \n",
                "        # Read only the target number of rows\n",
                "        df = pd.read_csv(file_path, nrows=target_rows, encoding='latin-1')\n",
                "        \n",
                "        # Save truncated file\n",
                "        df.to_csv(file_path, index=False, encoding='latin-1')\n",
                "        \n",
                "        new_size = os.path.getsize(file_path)\n",
                "        new_size_mb = new_size / BYTES_PER_MB\n",
                "        print(f\"  Truncated Size: {new_size_mb:.2f} MB\")\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"  Error processing file: {e}\")\n",
                "\n",
                "# Run truncation\n",
                "truncate_file(CITIZEN_FILE)\n",
                "truncate_file(PROVISION_FILE)\n",
                "truncate_file(FINAL_DF_FILE)\n",
                "   "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
